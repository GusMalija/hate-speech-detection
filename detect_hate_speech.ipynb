{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "detect_hate_speech.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMnKkfkM3GxXnrWKBVtsIxS",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/GusMalija/hate-speech-detection/blob/main/detect_hate_speech.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oen0lLTJjEvp",
        "outputId": "25ec3049-2a6c-4b74-a0eb-123d16f7ad8b"
      },
      "source": [
        "#calling important libraries\n",
        "import pandas as pd #for data manipulation\n",
        "import numpy as np #for data manipulation\n",
        "import matplotlib as plt #for plotting\n",
        "import os #for ease of python system interaction\n",
        "import sys\n",
        "import re\n",
        "import nltk\n",
        "nltk.download(\"stopwords\")\n",
        "import pickle\n",
        "from nltk.corpus import stopwords\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.svm import SVC\n",
        "from sklearn import svm\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.multiclass import OneVsRestClassifier\n",
        "from sklearn import svm"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "id": "ZSfRHiZinjcz",
        "outputId": "a3e995f7-f4bb-49c3-f79d-f682e0a82d16"
      },
      "source": [
        "#retrieving the data\n",
        "url = \"https://raw.githubusercontent.com/ApollineFo/NPL/main/data/labeled_data.csv\"\n",
        "\n",
        "data = pd.read_csv(url)\n",
        "#checking the dataset features\n",
        "data.keys()\n",
        "\n",
        "#removing offensive tweets\n",
        "data = data[data[\"class\"] !=1]\n",
        "data.head()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>count</th>\n",
              "      <th>hate_speech</th>\n",
              "      <th>offensive_language</th>\n",
              "      <th>neither</th>\n",
              "      <th>class</th>\n",
              "      <th>tweet</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>!!! RT @mayasolovely: As a woman you shouldn't...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>40</th>\n",
              "      <td>40</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>\" momma said no pussy cats inside my doghouse \"</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>63</th>\n",
              "      <td>63</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>\"@Addicted2Guys: -SimplyAddictedToGuys http://...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>66</th>\n",
              "      <td>66</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>\"@AllAboutManFeet: http://t.co/3gzUpfuMev\" woo...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>67</th>\n",
              "      <td>67</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>\"@Allyhaaaaa: Lemmie eat a Oreo &amp;amp; do these...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    Unnamed: 0  count  ...  class                                              tweet\n",
              "0            0      3  ...      2  !!! RT @mayasolovely: As a woman you shouldn't...\n",
              "40          40      3  ...      2    \" momma said no pussy cats inside my doghouse \"\n",
              "63          63      3  ...      2  \"@Addicted2Guys: -SimplyAddictedToGuys http://...\n",
              "66          66      3  ...      2  \"@AllAboutManFeet: http://t.co/3gzUpfuMev\" woo...\n",
              "67          67      3  ...      2  \"@Allyhaaaaa: Lemmie eat a Oreo &amp; do these...\n",
              "\n",
              "[5 rows x 7 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yI1eEvQsUBjY"
      },
      "source": [
        "#extracting only tweets as features\n",
        "features = data.iloc[:,6].values\n",
        "#extracting labels\n",
        "classes = data.iloc[:,5].values"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UIvOk8fSdzqV"
      },
      "source": [
        "Removal of unwanted text from data leads to clean textual data that can easily be transformed to numeric arrays ready to be subjected to machine learning techniques. Thus, we end up with results from which we can deduce the extent to which hate speech was detected. Corollary text preprocessing offers the opportunity for the modelâ€™s optimality to be tested.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UdI4T0vGWqNE"
      },
      "source": [
        "#preprocessing tweets\n",
        "processed_features = []\n",
        "\n",
        "for sentence in range(0, len(features)):\n",
        "    #Removing special characters\n",
        "    processed_feature = re.sub(r'\\W', ' ', str(features[sentence]))\n",
        "    #removing single characters\n",
        "    processed_feature= re.sub(r'\\s+[a-zA-Z]\\s+', ' ', processed_feature)\n",
        "    #Removing single characters from the start\n",
        "    processed_feature = re.sub(r'\\^[a-zA-Z]\\s+', ' ', processed_feature) \n",
        "    #Substituting multiple spaces with single space\n",
        "    processed_feature = re.sub(r'\\s+', ' ', processed_feature, flags=re.I)\n",
        "    #Removing prefixed 'b'\n",
        "    processed_feature = re.sub(r'^b\\s+', '', processed_feature)\n",
        "    #Converting to Lowercase\n",
        "    processed_feature = processed_feature.lower()\n",
        "\n",
        "    processed_features.append(processed_feature)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2khYxN6sbP7q"
      },
      "source": [
        "Both Gaussian and Linear kernels were specified to take care of irregularities that may have arisen from the dataset the machine learning model runs. With a Gaussian kernel, I specified a kernel coefficient \"gamma\" of zero. I set the class weight to \"balanced\" to automatically adjust weights/probabilities inversely proportional to class frequencies. I did not have to specify further for a linear kernel since it regards the dataset as a regular one with no imbalances.\n",
        "\n",
        "Since I have more than one class of tweets categorization - hate speech and neutral, I built a pipeline that applies a TF-IDF vectorizer taking into account the parameters I specified. It also uses an OneVsRest classier of SVC that takes into account probabilities/weights. With these in check, I separated my dataset to train and test sets where I have 80 percent of the data as a training set while 20 percent of it as a test set. I then use a Grid Search to do an exhaustive search over parameter values where all processors are used. To be concise, I control the verbosity of messages by only allowing computation time and parameter candidates for each fold to be displayed. The use of Grid search is deemed paramount since it picks the best performing kernel out of the Gaussian and linear ones I specified earlier. The output it produces is one for the best-performing kernel. In this regard, I did not have to worry about being explicit of a single kernel among the two. I then built a classifier by fitting my training sets from which I was able to predict my test set.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CVqwCRVe8jyO"
      },
      "source": [
        "#specifying parameters\n",
        "parameters = [\n",
        "    {\n",
        "    'vect__max_df': (0.9,), #ignore terms with frequency higher than aforementioned\n",
        "        'vect__min_df': (2,), #ignore lower frequencies than aforementioned\n",
        "        'vect__ngram_range': ((1, 2),), #only unigrams\n",
        "        'clf__estimator__kernel': ['rbf'], #gausian kernel\n",
        "    'clf__estimator__gamma': [1e0,], #a gamma of zero\n",
        "        'clf__estimator__C': [1,],\n",
        "        'clf__estimator__class_weight': [None, \"balanced\"] #balanced weight\n",
        "    },\n",
        "    {\n",
        "        'vect__max_df': (0.9,),\n",
        "        'vect__min_df': (2,),\n",
        "        'vect__ngram_range': ((1, 2),),\n",
        "        'clf__estimator__kernel': ['linear'], #linear kernel\n",
        "    'clf__estimator__C': [1,]\n",
        "    }\n",
        "]"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZQv_UCVxeGUw"
      },
      "source": [
        "# building a pipeline\n",
        "pipeline = Pipeline([('vect', TfidfVectorizer(parameters)),                     \n",
        "    ('clf', OneVsRestClassifier(SVC(probability=True))),\n",
        "])"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TgTn8OKX8V01"
      },
      "source": [
        "#splitting the dataset to trian and test set\n",
        "#80 percent of data for training, 20 percent for testing\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(processed_features, classes, test_size=0.2, random_state=42)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WfRSuZDA7I5y"
      },
      "source": [
        "#grid search\n",
        "grid_search = GridSearchCV(pipeline, parameters, n_jobs=-1, verbose=1)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QBQCaWbPrpmj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d3703507-dc55-4ee0-b4d7-a6f33a5b6c88"
      },
      "source": [
        "#fitting the classifier\n",
        "classifier = grid_search.fit(X_train, y_train)\n",
        "\n",
        "#predicting\n",
        "y_predict = classifier.predict(X_test)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fitting 5 folds for each of 3 candidates, totalling 15 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done  15 out of  15 | elapsed:  1.7min finished\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pmnpiNahnXOe",
        "outputId": "c0caab53-1725-47fd-d7f1-e3d5e1eec7ce"
      },
      "source": [
        "#confusion matrix\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "print(confusion_matrix(y_test, y_predict))\n",
        "print(classification_report(y_test, y_predict))"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[222  65]\n",
            " [ 16 816]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.93      0.77      0.85       287\n",
            "           2       0.93      0.98      0.95       832\n",
            "\n",
            "    accuracy                           0.93      1119\n",
            "   macro avg       0.93      0.88      0.90      1119\n",
            "weighted avg       0.93      0.93      0.93      1119\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-BxYhCbd-mHl",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 623
        },
        "outputId": "8005fb3c-bfbc-4f85-f5c2-8d6c2bd8cf84"
      },
      "source": [
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "cm = confusion_matrix(y_test, y_predict)\n",
        "# Normalise\n",
        "cmn = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
        "cm.sum(axis=1)[:, np.newaxis]\n",
        "fig, ax = plt.subplots(figsize=(10,10))\n",
        "sns.heatmap(cmn, annot=True, fmt='.2f')\n",
        "plt.ylabel('Actual')\n",
        "plt.xlabel('Predicted')\n",
        "plt.show(block=False)\n",
        "plt.savefig('cmn.png')"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x720 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y-y-268DcO2m"
      },
      "source": [
        "From the normalized confusion matrix below, zeros represent tweets classified as hate speech while ones represent tweets classified as neutral. This is owning data annotation that was cross-checked through the inter-annotator agreement. We can see that the  model correctly predicted about 77 percent of tweets that related to hate speech. On the other hand, 98 percent of tweets that did not relate to hate speech (classified as neutral) were predicted correctly. No model is perfect, and this applies to this model too. In this light, about 2 percent of tweets that were related to hate speech were classified as neutral, while about 23 percent of neutral tweets were classified as hate speech. Several reasons could explain such a minor flaw, but an important one is tweets that are hard for a human annotators to annotate. Nevertheless, the baseline model performs pretty well since it achieves an accuracy score of 93 percent."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T_gREW9ajN0f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5a30d521-6642-423f-dafa-3537a1771dec"
      },
      "source": [
        "#evaluating the model with ROC AUC score\n",
        "from sklearn.metrics import roc_auc_score\n",
        "roc_auc_score(y_test, y_predict, multi_class=\"ovr\")\n",
        "\n",
        "#with a higher score than 0.5, signifies that our model is useful."
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8771441972661485"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u_Q_ybSdcuiG"
      },
      "source": [
        "With ROC AUC score, I am computing the area under the receiver operating characteristics from the prediction scores. This served as the first evaluation technique because it is easy to interpret, with a single score being above 0.5 means that the model is performing suitably well. As it turned out, the model performed well with this technique since the ROC AUC score was 0.882, meaning that the model is doing a very good job."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "05SkEsEdI2pL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "584de6c1-e338-47c7-9840-29b17f644d5b"
      },
      "source": [
        "#evaluating the model using cross validation\n",
        "from sklearn.model_selection import cross_val_score\n",
        "all_accuracies = cross_val_score(estimator=classifier, X=X_train, y=y_train, cv=5)\n",
        "\n",
        "#returning accuracies of the folds\n",
        "print(all_accuracies)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fitting 5 folds for each of 3 candidates, totalling 15 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done  15 out of  15 | elapsed:  1.1min finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Fitting 5 folds for each of 3 candidates, totalling 15 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done  15 out of  15 | elapsed:  1.1min finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Fitting 5 folds for each of 3 candidates, totalling 15 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done  15 out of  15 | elapsed:  1.1min finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Fitting 5 folds for each of 3 candidates, totalling 15 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done  15 out of  15 | elapsed:  1.1min finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Fitting 5 folds for each of 3 candidates, totalling 15 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done  15 out of  15 | elapsed:  1.1min finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[0.92625698 0.92849162 0.9273743  0.93072626 0.9261745 ]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YKInXdIkdG7C"
      },
      "source": [
        "Cross-validation was used to determine the level of model precision. By running cross-validation, standard deviation score can be obtainedâ€”the lower the standard deviation, the more precise the model. The model turned out to be good since the standard deviation score obtained was 0.004, which is relatively low, suggesting that the modelâ€™s precision is too high for standards. With such a precise standard deviation, the model can apply to an even larger dataset.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cN5safV2MM91",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f205ce75-9526-497c-8192-4b6b51f842da"
      },
      "source": [
        "#printing standard deviation of accuracies\n",
        "print(all_accuracies.std())\n",
        "\n",
        "#earning a low variance meaning; a good indicator that the model will perform similar on all test sets and the prediction obtained is not by chance"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.0016879328960567243\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}